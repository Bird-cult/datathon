{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "#os.listdir(\".\")\n",
    "#credit = pd.read_csv(\"Credit_DataSet.csv\")\n",
    "\n",
    "# TODO: READ THE PROCESSED CSV INSTEAD (FOR EXAMPLE WITH CONVERTED CURRENCY)!\n",
    "\n",
    "credit = pd.read_excel(\"./Credit/Credit_DataSet.xlsx\", sheetname=\"DATA\", skiprows=0)\n",
    "\n",
    "# Quickly select numeric columns\n",
    "\n",
    "to_keep = ['NBR_EMPLOYEES', 'COUNTRY_RISK_GROWTH_RATE',\n",
    "       'COUNTRY_RISK_DIVIDEND_YIELD', 'COUNTRY_RISK_PAYOUT_RATIO',\n",
    "       'VOLATILITY_30D', 'VOLATILITY_180D', 'PCT_CHG_1_YEAR', 'PCT_CHG_6_M',\n",
    "       'DIVIDEND_YIELD', 'MARKETCAP', 'TOTAL_ASSETS', 'TOTAL_LIABILITIES',\n",
    "       'CURRENT_ASSETS', 'EBIT', 'RETAINED_EARNINGS', 'SALES', 'SALES_GROWTH',\n",
    "       'INTEREST_EXPENSES']\n",
    "\n",
    "X = credit[ to_keep + [\"DEFAULT_PROB\"] ].dropna()\n",
    "\n",
    "Y = X[\"DEFAULT_PROB\"].values\n",
    "X = X[to_keep].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ PREPROCESSED DATA FROM R FOR NN\n",
    "X_df = pd.read_csv(\"some_X.csv\", usecols=['NBR_EMPLOYEES', 'EMPL_GROWTH',\n",
    "       'COUNTRY_RISK_GROWTH_RATE', 'COUNTRY_RISK_DIVIDEND_YIELD',\n",
    "       'COUNTRY_RISK_PAYOUT_RATIO', 'VOLATILITY_30D', 'VOLATILITY_180D',\n",
    "       'PCT_CHG_1_YEAR', 'PCT_CHG_6_M', 'DIVIDEND_YIELD', 'MARKETCAP',\n",
    "       'TOTAL_ASSETS', 'TOTAL_LIABILITIES', 'CURRENT_ASSETS', 'EBIT',\n",
    "       'RETAINED_EARNINGS', 'SALES', 'SALES_GROWTH', 'INTEREST_EXPENSES'])\n",
    "Y_df = pd.read_csv(\"some_Y.csv\", usecols=[1])\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "X = Variable(torch.FloatTensor(X_df.values)).cuda()\n",
    "Y = Variable(torch.FloatTensor(Y_df.values)).cuda() # Always stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_most_likely(mlp, loss_fn, x_row, y_row):\n",
    "    candidates = [] # TODO: For every -1 in row in the specific columns, try 0 and 1\n",
    "    best_candidate = None\n",
    "    lowest_loss = 100000000000\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        input = candidate # TODO: Convert to one hot encoding\n",
    "        # Forward the candidate through the network\n",
    "        y_pred = mlp(input)\n",
    "        loss = loss_fn(y_pred, y_row)\n",
    "        if loss < lowest_loss:\n",
    "            best_candidate = input\n",
    "    return input\n",
    "\n",
    "def get_E_step(mlp, loss_fn, X, Y):\n",
    "    df_list = []\n",
    "    for x_row, y_row in zip(X.iterrorws(), Y.iterrows()):\n",
    "        df_list.append(select_most_likely(mlp, loss_fn, x_row, y_row))\n",
    "\n",
    "    return pd.DataFrame(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2612.3718\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 118.1737\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 40.3395\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 24.1766\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 17.2968\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 13.5008\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 11.0976\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 9.4382\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 8.2215\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 7.2899\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_M_step(mlp, loss_fn, X, Y):\n",
    "    learning_rate = 1e-4\n",
    "    for t in range(N_iter):\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, Y)\n",
    "        if (t % (N_iter / 10) == 0): print(loss)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in model.parameters():\n",
    "            param.data -= learning_rate * param.grad.data\n",
    "    return mlp\n",
    "\n",
    "def EM_algorithm():\n",
    "    # Make an initial model\n",
    "    N_hidden = 5\n",
    "    N_iter = 50000\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(X.shape[1], N_hidden),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(N_hidden, Y.shape[1]),\n",
    "    )\n",
    "\n",
    "    model = model.cuda()\n",
    "    loss_fn = torch.nn.SoftMarginLoss(size_average=False)\n",
    "    \n",
    "    # Init\n",
    "    \n",
    "    for (i in range(100)):\n",
    "        # Get the expected data\n",
    "        print(\"Doing iteration {} E step\".format(i))\n",
    "        X = Variable(torch.FloatTensor(get_E_step(model, loss_fn, X_df, Y_df).values)).cuda()\n",
    "        # TODO: Check if the predicted data is the same still?\n",
    "        # Train the model for some iterations\n",
    "        model = get_M_step(mlp, loss_fn, X, Y)\n",
    "        print(\"Doing iteration {} M step\".format(i))\n",
    "\n",
    "        # Get new data\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.7050e-01 -3.8609e-02 -4.8866e+00  ...  -2.6039e-01 -2.5953e-02  3.3389e-01\n",
       "-3.4296e-01 -5.3851e-02  2.9936e-01  ...  -2.7932e-01 -8.0263e-02 -8.4846e-02\n",
       "-3.2822e-01 -3.6055e-02 -4.8866e+00  ...  -2.9783e-01 -2.1485e-01  6.4142e-02\n",
       "                ...                   â‹±                   ...                \n",
       "-3.2185e-01 -2.7771e-02  2.9936e-01  ...  -2.5427e-01  1.1513e-02 -2.2298e-01\n",
       "-3.1000e-01  5.7829e+01  2.9936e-01  ...  -2.5438e-01 -6.2910e-02 -2.3600e-01\n",
       " 2.8382e-01 -3.1864e-02  1.2225e+00  ...  -2.6706e-01 -6.4205e-02 -2.0394e-01\n",
       "[torch.FloatTensor of size (3780,19)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
