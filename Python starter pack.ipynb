{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "#os.listdir(\".\")\n",
    "#credit = pd.read_csv(\"Credit_DataSet.csv\")\n",
    "\n",
    "# TODO: READ THE PROCESSED CSV INSTEAD (FOR EXAMPLE WITH CONVERTED CURRENCY)!\n",
    "\n",
    "credit = pd.read_excel(\"./Credit/Credit_DataSet.xlsx\", sheetname=\"DATA\", skiprows=0)\n",
    "\n",
    "# Quickly select numeric columns\n",
    "\n",
    "to_keep = ['NBR_EMPLOYEES', 'COUNTRY_RISK_GROWTH_RATE',\n",
    "       'COUNTRY_RISK_DIVIDEND_YIELD', 'COUNTRY_RISK_PAYOUT_RATIO',\n",
    "       'VOLATILITY_30D', 'VOLATILITY_180D', 'PCT_CHG_1_YEAR', 'PCT_CHG_6_M',\n",
    "       'DIVIDEND_YIELD', 'MARKETCAP', 'TOTAL_ASSETS', 'TOTAL_LIABILITIES',\n",
    "       'CURRENT_ASSETS', 'EBIT', 'RETAINED_EARNINGS', 'SALES', 'SALES_GROWTH',\n",
    "       'INTEREST_EXPENSES']\n",
    "\n",
    "X = credit[ to_keep + [\"DEFAULT_PROB\"] ].dropna()\n",
    "\n",
    "Y = X[\"DEFAULT_PROB\"].values\n",
    "X = X[to_keep].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# READ PREPROCESSED DATA FROM R FOR NN\n",
    "X_df = pd.read_csv(\"some_X.csv\", usecols=['NBR_EMPLOYEES', 'EMPL_GROWTH',\n",
    "       'COUNTRY_RISK_GROWTH_RATE', 'COUNTRY_RISK_DIVIDEND_YIELD',\n",
    "       'COUNTRY_RISK_PAYOUT_RATIO', 'VOLATILITY_30D', 'VOLATILITY_180D',\n",
    "       'PCT_CHG_1_YEAR', 'PCT_CHG_6_M', 'DIVIDEND_YIELD', 'MARKETCAP',\n",
    "       'TOTAL_ASSETS', 'TOTAL_LIABILITIES', 'CURRENT_ASSETS', 'EBIT',\n",
    "       'RETAINED_EARNINGS', 'SALES', 'SALES_GROWTH', 'INTEREST_EXPENSES',\n",
    "        'WHISTLE_BLOWER_POLICY', 'ETHICS_POLICY', 'BRIBERY_POLICY'])\n",
    "Y_df = pd.read_csv(\"some_Y.csv\", usecols=[1])\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_most_likely(mlp, loss_fn, x_row, y_row):\n",
    "    candidates = [] # TODO: For every -1 in row in the specific columns, try 0 and 1\n",
    "    \n",
    "    bad_values = {'WHISTLE_BLOWER_POLICY': 0,\n",
    "                            'ETHICS_POLICY': 0,\n",
    "                            'BRIBERY_POLICY': 0}\n",
    "\n",
    "    possible_values_dict = {'WHISTLE_BLOWER_POLICY':[[1,0], [0,1]],\n",
    "                            'ETHICS_POLICY':[[1,0], [0,1]],\n",
    "                            'BRIBERY_POLICY':[[1,0], [0,1]]}\n",
    "    \n",
    "    # Make a dictionary for the candidate values that we will expand later\n",
    "    candidate_dict = {}\n",
    "    for k, v in x_row.iteritems():\n",
    "        candidate_dict[k] = []\n",
    "        \n",
    "        if (k in bad_values): # We have to encode for the neural network\n",
    "            if (v == bad_values[k]):\n",
    "                for i in possible_values_dict[k]:\n",
    "                    # Directly encode the bad_value\n",
    "                    candidate_dict[k].append(i)\n",
    "            else:\n",
    "                candidate_dict[k] = [possible_values_dict[k][int(v) - 1]] # HACK: IT'S BECAUSE THEY HAVE VALUES 1 AND 2\n",
    "        else:\n",
    "            # Just add the value\n",
    "            candidate_dict[k].append([v])\n",
    "\n",
    "    best_candidate = None\n",
    "    lowest_loss = 100000000000\n",
    "\n",
    "    # In the dictionary we have the different candidates\n",
    "    for candidate in product(*candidate_dict.values()):\n",
    "        input = Variable(torch.FloatTensor(np.array(list(chain(*list(candidate)))))).cuda()\n",
    "        # Forward the candidate through the network        \n",
    "        y_pred = mlp(input)\n",
    "        loss = loss_fn(y_pred, y_row)\n",
    "        if loss < lowest_loss:\n",
    "            best_candidate = input\n",
    "    return best_candidate\n",
    "    \n",
    "def get_E_step(mlp, loss_fn, X_df, Y_df):\n",
    "    \"\"\" Return a torch CUDA variable of X\"\"\"\n",
    "    df_list = []        \n",
    "    for (k, j) in zip(X_df.iterrows(), Y_df.iterrows()):\n",
    "        (_, x) = k\n",
    "        (_, y) = j\n",
    "        df_list.append(select_most_likely(model, loss_fn, x, Variable(torch.FloatTensor(y.values)).cuda()))\n",
    "    return torch.stack(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_M_step(mlp, loss_fn, X, Y, N_iter):\n",
    "    learning_rate = 1e-5\n",
    "    for t in range(N_iter):\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, Y)\n",
    "        if (t % (N_iter / 2) == 0): print(loss)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in model.parameters():\n",
    "            param.data -= learning_rate * param.grad.data\n",
    "    return mlp, loss\n",
    "\n",
    "def EM_algorithm(X_df, Y_df, N_hidden=10, N_iter=10000):\n",
    "    \n",
    "    X = Variable(torch.FloatTensor(X_df.values)).cuda()\n",
    "    Y = Variable(torch.FloatTensor(Y_df.values)).cuda() # Always stays the same\n",
    "\n",
    "    # Make an initial model\n",
    "    print(\"Making model\")\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(X.shape[1] + 3, N_hidden),\n",
    "        torch.nn.ReLU(),\n",
    "        #torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(N_hidden, Y.shape[1]),\n",
    "        torch.nn.Sigmoid() # If it doesn't work, look here\n",
    "    )\n",
    "\n",
    "    model = model.cuda()\n",
    "    loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "    \n",
    "    previous_loss = 10000000\n",
    "    # Init\n",
    "    for i in range(100):\n",
    "        # Get the expected data\n",
    "        print(\"Doing iteration {} E step: finding most likely data\".format(i + 1))\n",
    "        X = get_E_step(model, loss_fn, X_df, Y_df)\n",
    "        # TODO: Check if the predicted data is the same still?\n",
    "        # Train the model for some iterations\n",
    "        print(\"Doing iteration {} M step: training neural network\".format(i + 1))\n",
    "        learning_rate = 1e-3\n",
    "        for t in range(N_iter):\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, Y)\n",
    "            if (t % (N_iter / 2) == 0): print(loss)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            for param in model.parameters():\n",
    "                param.data -= learning_rate * param.grad.data\n",
    "\n",
    "        if (-loss + previous_loss)<0.0001: \n",
    "            print(\"Loss not decreasing: exit\")\n",
    "            break\n",
    "        previous_loss = loss\n",
    "    return X, model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model\n",
      "Doing iteration 1 E step: finding most likely data\n",
      "Doing iteration 1 M step: training neural network\n",
      "Variable containing:\n",
      " 850.1283\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.5227\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 2 E step: finding most likely data\n",
      "Doing iteration 2 M step: training neural network\n",
      "Variable containing:\n",
      " 0.4614\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.4440\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 3 E step: finding most likely data\n",
      "Doing iteration 3 M step: training neural network\n",
      "Variable containing:\n",
      " 0.4314\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.4209\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 4 E step: finding most likely data\n",
      "Doing iteration 4 M step: training neural network\n",
      "Variable containing:\n",
      " 0.4109\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.4015\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 5 E step: finding most likely data\n",
      "Doing iteration 5 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3924\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.3832\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 6 E step: finding most likely data\n",
      "Doing iteration 6 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3751\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.3678\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 7 E step: finding most likely data\n",
      "Doing iteration 7 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3609\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.3539\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 8 E step: finding most likely data\n",
      "Doing iteration 8 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3477\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.3418\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 9 E step: finding most likely data\n",
      "Doing iteration 9 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3357\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.3296\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 10 E step: finding most likely data\n",
      "Doing iteration 10 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3238\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.3178\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 11 E step: finding most likely data\n",
      "Doing iteration 11 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3120\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.3064\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 12 E step: finding most likely data\n",
      "Doing iteration 12 M step: training neural network\n",
      "Variable containing:\n",
      " 0.3010\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.2954\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 13 E step: finding most likely data\n",
      "Doing iteration 13 M step: training neural network\n",
      "Variable containing:\n",
      " 0.2898\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.2842\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 14 E step: finding most likely data\n",
      "Doing iteration 14 M step: training neural network\n",
      "Variable containing:\n",
      " 0.2793\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.2747\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 15 E step: finding most likely data\n",
      "Doing iteration 15 M step: training neural network\n",
      "Variable containing:\n",
      " 0.2702\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.2657\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 16 E step: finding most likely data\n",
      "Doing iteration 16 M step: training neural network\n",
      "Variable containing:\n",
      " 0.2615\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.2572\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Doing iteration 17 E step: finding most likely data\n",
      "Doing iteration 17 M step: training neural network\n",
      "Variable containing:\n",
      " 0.2535\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0.2502\n",
      "[torch.cuda.FloatTensor of size () (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-54d4b435039d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-105-09d6f85d47c7>\u001b[0m in \u001b[0;36mEM_algorithm\u001b[0;34m(X_df, Y_df, N_hidden, N_iter)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN_iter\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 83\u001b[0;31m         variables, grad_variables, retain_graph, create_graph)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_final, mlp = EM_algorithm(X_df, Y_df, N_hidden=80, N_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = X_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "def two_columns_to_one(bla):\n",
    "    if bla.equal(torch.FloatTensor([1,0]).cuda()):\n",
    "        return 1\n",
    "    elif bla.equal(torch.FloatTensor([0,1]).cuda()):\n",
    "        return 2\n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def pytorch_vars_to_df(X_df, X):\n",
    "    new_df = X_df.copy()\n",
    "    # Map categorical variables back\n",
    "    cat = {'WHISTLE_BLOWER_POLICY','ETHICS_POLICY','BRIBERY_POLICY'}\n",
    "    new_df['WHISTLE_BLOWER_POLICY'] = pd.Series([two_columns_to_one(x) for x in X_final[:, 19:21].data])\n",
    "    new_df['ETHICS_POLICY'] = pd.Series([two_columns_to_one(x) for x in X_final[:, 21:23].data])\n",
    "    new_df['BRIBERY_POLICY'] = pd.Series([two_columns_to_one(x) for x in X_final[:, 23:25].data])\n",
    "\n",
    "    return X_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "5       1\n",
       "6       1\n",
       "7       1\n",
       "8       1\n",
       "9       1\n",
       "10      1\n",
       "11      1\n",
       "12      1\n",
       "13      1\n",
       "14      1\n",
       "15      1\n",
       "16      2\n",
       "17      1\n",
       "18      1\n",
       "19      1\n",
       "20      1\n",
       "21      1\n",
       "22      1\n",
       "23      1\n",
       "24      1\n",
       "25      1\n",
       "26      1\n",
       "27      1\n",
       "28      1\n",
       "29      1\n",
       "       ..\n",
       "3903    1\n",
       "3904    1\n",
       "3905    1\n",
       "3906    1\n",
       "3907    1\n",
       "3908    1\n",
       "3909    1\n",
       "3910    1\n",
       "3911    1\n",
       "3912    1\n",
       "3913    1\n",
       "3914    2\n",
       "3915    1\n",
       "3916    1\n",
       "3917    1\n",
       "3918    1\n",
       "3919    1\n",
       "3920    1\n",
       "3921    1\n",
       "3922    2\n",
       "3923    1\n",
       "3924    1\n",
       "3925    1\n",
       "3926    1\n",
       "3927    1\n",
       "3928    1\n",
       "3929    1\n",
       "3930    1\n",
       "3931    1\n",
       "3932    1\n",
       "Length: 3933, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 0\n",
       "[torch.cuda.FloatTensor of size (2,) (GPU 0)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
